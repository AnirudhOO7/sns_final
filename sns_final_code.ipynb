{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErSZegsMIhvL",
        "outputId": "4982fb91-0e43-4105-e079-5c946664435c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features extracted and saved to email_features.csv\n",
            "Total emails processed: 24\n",
            "\n",
            "Feature summary:\n",
            "              id  char_count  word_count  url_count  exclamation_count  \\\n",
            "count  24.000000   24.000000   24.000000  24.000000               24.0   \n",
            "mean   12.500000  130.625000   19.416667   0.500000                0.0   \n",
            "std     7.071068   18.728756    3.786896   0.510754                0.0   \n",
            "min     1.000000  101.000000   14.000000   0.000000                0.0   \n",
            "25%     6.750000  115.000000   16.000000   0.000000                0.0   \n",
            "50%    12.500000  131.500000   19.500000   0.500000                0.0   \n",
            "75%    18.250000  141.750000   21.250000   1.000000                0.0   \n",
            "max    24.000000  178.000000   28.000000   1.000000                0.0   \n",
            "\n",
            "       urgency_keyword_count  has_financial_keywords  has_login_request  \\\n",
            "count              24.000000               24.000000          24.000000   \n",
            "mean                1.958333                0.458333           0.250000   \n",
            "std                 2.074256                0.508977           0.442326   \n",
            "min                 0.000000                0.000000           0.000000   \n",
            "25%                 0.000000                0.000000           0.000000   \n",
            "50%                 1.000000                0.000000           0.000000   \n",
            "75%                 4.000000                1.000000           0.250000   \n",
            "max                 7.000000                1.000000           1.000000   \n",
            "\n",
            "           label  \n",
            "count  24.000000  \n",
            "mean    0.500000  \n",
            "std     0.510754  \n",
            "min     0.000000  \n",
            "25%     0.000000  \n",
            "50%     0.500000  \n",
            "75%     1.000000  \n",
            "max     1.000000  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def count_urls(text):\n",
        "    return len(re.findall(r'http[s]?://', text.lower()))\n",
        "\n",
        "def count_exclamations(text):\n",
        "    return text.count('!')\n",
        "\n",
        "def count_urgency_keywords(text):\n",
        "    urgency_words = ['immediately', 'urgent', 'verify', 'suspend', 'confirm',\n",
        "                     'update', 'password', 'alert', 'action required', 'final notice',\n",
        "                     'expires', 'within', 'hours', 'critical']\n",
        "    text_lower = text.lower()\n",
        "    count = sum(text_lower.count(word) for word in urgency_words)\n",
        "    return count\n",
        "\n",
        "def has_financial_keywords(text):\n",
        "    financial_words = ['invoice', 'payment', 'transfer', 'bank', 'account',\n",
        "                       'billing', 'subscription', 'charge', '$']\n",
        "    text_lower = text.lower()\n",
        "    return 1 if any(word in text_lower for word in financial_words) else 0\n",
        "\n",
        "def has_login_request(text):\n",
        "    login_phrases = ['click here', 'click the link', 'click to', 'log in',\n",
        "                     'sign in', 'login', 'click below']\n",
        "    text_lower = text.lower()\n",
        "    return 1 if any(phrase in text_lower for phrase in login_phrases) else 0\n",
        "\n",
        "def extract_features(text):\n",
        "    features = {\n",
        "        'char_count': len(text),\n",
        "        'word_count': len(text.split()),\n",
        "        'url_count': count_urls(text),\n",
        "        'exclamation_count': count_exclamations(text),\n",
        "        'urgency_keyword_count': count_urgency_keywords(text),\n",
        "        'has_financial_keywords': has_financial_keywords(text),\n",
        "        'has_login_request': has_login_request(text)\n",
        "    }\n",
        "    return features\n",
        "\n",
        "def process_dataset(input_file, output_file):\n",
        "    df = pd.read_csv(input_file)\n",
        "\n",
        "    features_list = []\n",
        "    for idx, row in df.iterrows():\n",
        "        features = extract_features(row['text'])\n",
        "        features['id'] = row['id']\n",
        "        features['label'] = row['label']\n",
        "        features_list.append(features)\n",
        "\n",
        "    features_df = pd.DataFrame(features_list)\n",
        "\n",
        "    cols = ['id', 'char_count', 'word_count', 'url_count', 'exclamation_count',\n",
        "            'urgency_keyword_count', 'has_financial_keywords', 'has_login_request', 'label']\n",
        "    features_df = features_df[cols]\n",
        "\n",
        "    features_df.to_csv(output_file, index=False)\n",
        "    print(f\"Features extracted and saved to {output_file}\")\n",
        "    print(f\"Total emails processed: {len(features_df)}\")\n",
        "    print(f\"\\nFeature summary:\")\n",
        "    print(features_df.describe())\n",
        "\n",
        "    return features_df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    process_dataset('email_dataset.csv', 'email_features.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def train_and_evaluate():\n",
        "    df = pd.read_csv('email_features.csv')\n",
        "\n",
        "    feature_columns = ['char_count', 'word_count', 'url_count', 'exclamation_count',\n",
        "                       'urgency_keyword_count', 'has_financial_keywords', 'has_login_request']\n",
        "    X = df[feature_columns]\n",
        "    y = df['label']\n",
        "\n",
        "    print(\"Dataset Info:\")\n",
        "    print(f\"Total samples: {len(df)}\")\n",
        "    print(f\"Phishing emails: {sum(y == 1)}\")\n",
        "    print(f\"Benign emails: {sum(y == 0)}\")\n",
        "    print()\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    print(f\"Training set: {len(X_train)} samples\")\n",
        "    print(f\"Test set: {len(X_test)} samples\")\n",
        "    print()\n",
        "\n",
        "    clf = LogisticRegression(random_state=42, max_iter=1000)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    print(\"=\"*50)\n",
        "    print(\"RESULTS\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"\\nAccuracy: {accuracy:.2%}\")\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=['Benign', 'Phishing']))\n",
        "\n",
        "    print(\"\\nFeature Importance (Coefficients):\")\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': feature_columns,\n",
        "        'coefficient': clf.coef_[0]\n",
        "    }).sort_values('coefficient', ascending=False)\n",
        "    print(feature_importance)\n",
        "\n",
        "    test_results = pd.DataFrame({\n",
        "        'id': df.iloc[X_test.index]['id'],\n",
        "        'actual': y_test.values,\n",
        "        'predicted': y_pred,\n",
        "        'correct': y_test.values == y_pred\n",
        "    })\n",
        "    test_results.to_csv('test_predictions.csv', index=False)\n",
        "    print(\"\\nTest predictions saved to test_predictions.csv\")\n",
        "\n",
        "    return clf, accuracy, feature_importance\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    clf, accuracy, feature_importance = train_and_evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qm_LxHa6JjXj",
        "outputId": "49c82acd-54ee-491e-dd0e-92d3d77ba940"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Info:\n",
            "Total samples: 24\n",
            "Phishing emails: 12\n",
            "Benign emails: 12\n",
            "\n",
            "Training set: 16 samples\n",
            "Test set: 8 samples\n",
            "\n",
            "==================================================\n",
            "RESULTS\n",
            "==================================================\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "Confusion Matrix:\n",
            "[[4 0]\n",
            " [0 4]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Benign       1.00      1.00      1.00         4\n",
            "    Phishing       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00         8\n",
            "   macro avg       1.00      1.00      1.00         8\n",
            "weighted avg       1.00      1.00      1.00         8\n",
            "\n",
            "\n",
            "Feature Importance (Coefficients):\n",
            "                  feature  coefficient\n",
            "4   urgency_keyword_count     0.380464\n",
            "0              char_count     0.226451\n",
            "2               url_count     0.162721\n",
            "5  has_financial_keywords     0.156861\n",
            "6       has_login_request     0.075206\n",
            "3       exclamation_count     0.000000\n",
            "1              word_count    -0.883157\n",
            "\n",
            "Test predictions saved to test_predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def create_visualizations():\n",
        "    features_df = pd.read_csv('email_features.csv')\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "    phishing = features_df[features_df['label'] == 1]\n",
        "    benign = features_df[features_df['label'] == 0]\n",
        "\n",
        "    axes[0, 0].bar(['Phishing', 'Benign'],\n",
        "                   [phishing['url_count'].mean(), benign['url_count'].mean()],\n",
        "                   color=['red', 'green'])\n",
        "    axes[0, 0].set_title('Average URL Count')\n",
        "    axes[0, 0].set_ylabel('Count')\n",
        "\n",
        "    axes[0, 1].bar(['Phishing', 'Benign'],\n",
        "                   [phishing['urgency_keyword_count'].mean(), benign['urgency_keyword_count'].mean()],\n",
        "                   color=['red', 'green'])\n",
        "    axes[0, 1].set_title('Average Urgency Keywords')\n",
        "    axes[0, 1].set_ylabel('Count')\n",
        "\n",
        "    axes[1, 0].bar(['Phishing', 'Benign'],\n",
        "                   [phishing['has_financial_keywords'].mean() * 100,\n",
        "                    benign['has_financial_keywords'].mean() * 100],\n",
        "                   color=['red', 'green'])\n",
        "    axes[1, 0].set_title('Emails with Financial Keywords')\n",
        "    axes[1, 0].set_ylabel('Percentage')\n",
        "\n",
        "    axes[1, 1].bar(['Phishing', 'Benign'],\n",
        "                   [phishing['has_login_request'].mean() * 100,\n",
        "                    benign['has_login_request'].mean() * 100],\n",
        "                   color=['red', 'green'])\n",
        "    axes[1, 1].set_title('Emails with Login Requests')\n",
        "    axes[1, 1].set_ylabel('Percentage')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('feature_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"Visualization saved to feature_comparison.png\")\n",
        "    plt.close()\n",
        "\n",
        "    predictions = pd.read_csv('test_predictions.csv')\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    import seaborn as sns\n",
        "\n",
        "    cm = confusion_matrix(predictions['actual'], predictions['predicted'])\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Benign', 'Phishing'],\n",
        "                yticklabels=['Benign', 'Phishing'])\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"Confusion matrix saved to confusion_matrix.png\")\n",
        "    plt.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    create_visualizations()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YB3evl_Juhf",
        "outputId": "8cd260d7-a957-40e1-b994-3bc18e9698f6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visualization saved to feature_comparison.png\n",
            "Confusion matrix saved to confusion_matrix.png\n"
          ]
        }
      ]
    }
  ]
}